# GCN(Graph Convolutional Network)

## 1. GCN이란?

GCN(Graph Convolutional Network)은 그래프 구조를 활용하여 **노드가 자신의 이웃 노드들의 특성을 반영해 자신을 업데이트**하는 딥러닝 모델입니다. 그래프의 각 노드는 특정 특성 벡터를 가지고, 인접 행렬을 통해 노드 간 연결 관계를 표현합니다. 이를 통해 같은 종류의 노드라도 **이웃에 따라 다른 특성 표현을 학습**할 수 있습니다.

## 2. 인접 행렬과 자기 연결

- **인접 행렬** \( A \): 그래프의 노드 간 연결을 0과 1로 표현하는 행렬.
- **자기 연결(Self-Loop)**: 각 노드가 자신의 특성을 반영할 수 있도록 인접 행렬에 대각선 성분이 모두 1인 단위 행렬 \( I \)을 더해, 자기 자신과의 연결을 추가합니다.

예를 들어, 다음과 같은 인접 행렬 \( A \)이 있을 때:

$$A = \begin{pmatrix} 0 & 1 & 1 \\ 1 & 0 & 0 \\ 1 & 0 & 0 \end{pmatrix}$$


단위 행렬 \( I \) 를 더하여 자기 연결을 추가합니다.

$$
A + I = $\begin{pmatrix} 0 & 1 & 1 \\ 1 & 0 & 0 \\ 1 & 0 & 0 \end{pmatrix} + \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix} = \begin{pmatrix} 1 & 1 & 1 \\ 1 & 1 & 0 \\ 1 & 0 & 1 \end{pmatrix}
$$

이제 각 노드는 자기 자신과도 연결된 상태가 되어, 정보를 전파할 때 자기 자신의 특성을 반영할 수 있습니다.

## 3. 정규화된 인접 행렬

**인접 행렬에 자기 연결을 추가하여 \( \tilde{A} \)를 만든 뒤**, **정규화 행렬 \( D^{-1/2} \)**을 양쪽에 곱하여 정규화된 인접 행렬 \( \tilde{A}_{norm} \)를 만듭니다. 여기서 \( D \)는 각 노드의 이웃 수를 대각선에 나타낸 행렬입니다. 이를 통해 각 노드는 **이웃의 수에 비례해 정보를 고르게 반영**하게 됩니다.

예를 들어, 다음과 같은 **자기 연결을 추가한 인접행렬 \( \tilde{A} \)**와 그에 대한 **대각행렬 \( D \)**가 있을 때, 정규화 행렬 \( D^{-1/2} \)는 다음과 같습니다.

$
D = \begin{pmatrix} 3 & 0 & 0 \\ 0 & 2 & 0 \\ 0 & 0 & 2 \end{pmatrix}, \quad D^{-1/2} = \begin{pmatrix} \frac{1}{\sqrt{3}} & 0 & 0 \\ 0 & \frac{1}{\sqrt{2}} & 0 \\ 0 & 0 & \frac{1}{\sqrt{2}} \end{pmatrix}
$

정규화된 인접 행렬은 양쪽에서 정규화 행렬을 곱하여 계산됩니다:

$
\tilde{A}_{norm} = D^{-1/2} (A + I) D^{-1/2} = \begin{pmatrix} 0.333 & 0.408 & 0.408 \\ 0.408 & 0.5 & 0 \\ 0.408 & 0 & 0.5 \end{pmatrix}
$

### 양쪽 정규화 이유

정규화 행렬을 양쪽에 곱하면 정보가 **노드 간에 균형 있게 전파**됩니다. 노드가 정보를 받을 때뿐만 아니라 보낼 때도 이웃 수에 따른 균형이 맞춰지기 때문입니다.

## 4. 정보 교환의 의미

**정보 교환**은 노드가 **이웃 노드의 특성을 반영해 자신을 업데이트**하는 과정을 뜻합니다. 예를 들어, 산소 원자(O)가 수소 원자(H)들과 결합된 물 분자(H₂O)와 산소 원자들끼리 결합된 산소 분자(O₂)의 경우, GCN을 통해 산소 원자는 각 결합 상태에 따라 다른 특성을 학습할 수 있습니다.

- 물 분자에서 산소 원자는 **수소 원자들로부터 정보를 받아 업데이트**되어, 물 분자에서의 특성을 반영합니다.
- 산소 분자에서는 **이웃한 산소 원자와의 정보를 교환**하여 산소 분자 특성을 학습하게 됩니다.

## 5. GCN에서의 순전파 과정

순전파 과정은 각 노드가 이웃한 노드들과 정보를 주고받으며 자신을 업데이트 하는 과정입니다. **정규화된 인접행렬 \( \tilde{A}_{norm} \)**과 **가중치 행렬**을 사용하여 그래프 합성곱을 통해 진행됩니다.

$
H^{(l+1)} = \sigma(\tilde{A}_{norm} H^{(l)} W^{(l)})
$

여기서:
- \( H^{(l)} \): 현재 레이어의 노드 특성 행렬 (초기 입력은 \( H^{(0)} = X \))
- \( W^{(l)} \): 현재 레이어의 가중치 행렬
- \( \sigma \): 활성화 함수 (예: ReLU)

순전파 과정에서는, 초기 특성 행렬 \( H^{(0)} \)에서 시작하여 매 레이어를 거칠 때마다 새로운 가중치와 정규화된 인접 행렬을 사용해 특성을 점차적으로 업데이트합니다.

### 예시
1. 각 노드가 가지는 특성 벡터 \( V \)가 있을 때, \( V_1, V_2, \dots, V_n \)을 묶어 초기 특성 행렬 \( H^{(0)} \)를 만듭니다.
2. 각 레이어에서 고유의 정규화된 인접 행렬 \( \tilde{A}_{norm} \)과 가중치 \( W^{(l)} \)를 사용해 \( H^{(l+1)} = \sigma(\tilde{A}_{norm} H^{(l)} W^{(l)}) \)를 계산합니다.
3. 최종 출력 층에 도달하면 모델은 손실 함수(Loss Function)을 계산하여 실제값과 예측값의 차이를 구합니다.
4. 역전파(Backpropagation)를 통해 가중치 행렬을 손실의 그래디언트 방향으로 업데이트하여 가중치를 조정합니다.
5. 업데이트된 가중치 행렬 \( W^{(l)} \)를 가지고 다음 Epoch를 시작하며, 이때 초기 특성 행렬 \( H^{(0)} \)는 동일하나, 새로운 가중치 행렬에 의해 매 Epoch마다 다른 값이 계산됩니다.

## 6. GNN과 GCN의 차이점

- **GNN(Graph Neural Network)**: 그래프에서 노드 간의 연결을 고려하여 정보를 전파하는 일반적인 신경망입니다.
- **GCN(Graph Convolutional Network)**: GNN의 한 종류로, **그래프 합성곱**을 통해 노드의 이웃 정보를 고르게 반영하는 방식에 초점을 맞춥니다. 정규화된 인접 행렬을 활용해 노드가 이웃의 특성을 고르게 반영하게 됩니다.

## GCN의 IC50 예측 모델 예시

이제 GCN을 이용해 small molecule의 **SARS-CoV-2에 대한 IC50 값을 예측하는 예시**를 살펴보겠습니다.

### 1. 특성 벡터와 그래프 구조

#### 특성 벡터
- 각 small molecule을 구성하는 **원자**들은 고유한 **특성 벡터**를 가지며, 이 벡터는 모델의 입력으로 사용됩니다.
- 예를 들어, 원자의 특성이 `[전기 음성도, 전자 친화도, 원자 반지름]` 세 가지로 구성된다면, 각 원자는 길이가 3인 벡터로 표현됩니다.

#### 그래프 구조: 인접 행렬과 대각 행렬
- 각 small molecule은 **원자 간 결합 구조**에 따라 고유한 그래프 구조를 가집니다. 이 그래프는 **인접 행렬** \( A \)로 표현되며, 원자 간의 연결 관계를 나타냅니다.
- 자기 연결(Self-Loop)을 추가하기 위해, 인접 행렬에 단위 행렬 \( I \)을 더하고, 이를 통해 대각 행렬 \( D \)를 계산하여 **정규화된 인접 행렬** \( \tilde{A}_{norm} \)을 구합니다:

$
\tilde{A}_{norm} = D^{-1/2} (A + I) D^{-1/2}
$

각 small molecule마다 고유한 그래프 구조를 미리 계산하여 모델에 입력으로 제공합니다.

### 2. 순전파 과정 (Forward Propagation)

각 레이어에서 정규화된 인접 행렬과 초기 특성 행렬을 사용해 각 노드(원자)가 이웃 노드의 정보를 반영하여 새로운 특성 벡터로 업데이트됩니다. 

### 3. IC50 예측을 위한 학습 과정

모델은 small molecule의 구조와 원자 특성에 기반해 IC50을 예측하며, 이를 위해 **손실 함수(Loss Function)**를 통해 예측값과 실제 IC50 값을 비교합니다.

#### 손실 함수와 가중치 업데이트
- 각 레이어의 가중치는 **손실 값이 최소화되는 방향으로 Epoch가 끝날 때마다 업데이트**됩니다.
- 손실 함수는 모델이 예측한 IC50 값과 실제 IC50 값의 차이를 계산하며, **역전파(Backpropagation)**를 통해 그래디언트를 구한 뒤, 옵티마이저를 사용하여 가중치를 조정합니다.
